{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Qb7VRmZKRNzs",
        "outputId": "2dbab650-8975-4ebc-fcde-13984eba954c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0 category                                               text\n",
              "1507        1507    other  нафтогаз заявить украинский сторона согласный ...\n",
              "1508        1508    other  страна опек договориться снижение объём добыча...\n",
              "1509        1509    other  меджлис крымскотатарский народ экстремистский ...\n",
              "1510        1510    other  недавно вернуться россия певица наталья ветлиц...\n",
              "1511        1511    other  канцлер германия ангела меркель впервые 14 год..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce6e8f6a-0d44-42a1-b086-c3ea4717b653\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1507</th>\n",
              "      <td>1507</td>\n",
              "      <td>other</td>\n",
              "      <td>нафтогаз заявить украинский сторона согласный ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1508</th>\n",
              "      <td>1508</td>\n",
              "      <td>other</td>\n",
              "      <td>страна опек договориться снижение объём добыча...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1509</th>\n",
              "      <td>1509</td>\n",
              "      <td>other</td>\n",
              "      <td>меджлис крымскотатарский народ экстремистский ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1510</th>\n",
              "      <td>1510</td>\n",
              "      <td>other</td>\n",
              "      <td>недавно вернуться россия певица наталья ветлиц...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1511</th>\n",
              "      <td>1511</td>\n",
              "      <td>other</td>\n",
              "      <td>канцлер германия ангела меркель впервые 14 год...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce6e8f6a-0d44-42a1-b086-c3ea4717b653')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce6e8f6a-0d44-42a1-b086-c3ea4717b653 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce6e8f6a-0d44-42a1-b086-c3ea4717b653');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/dataset_lemm.csv', encoding='utf-16')\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JneNFwmTLrf",
        "outputId": "6fcbe6fd-7e5b-4a84-9c3b-fb0719624e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vTp74trRNzt"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n",
        "labels = {\n",
        "          'study':0,\n",
        "          'other':1\n",
        "          }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuPwePx7RNzu"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['category']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itqN3wHFRNzu"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('DeepPavlov/rubert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd-TxOjmRNzv",
        "outputId": "3f11015f-1999-472b-ad2b-243bccad4981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1209 151 152\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
        "                                     [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train),len(df_val), len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ_B48PlRNzv",
        "outputId": "8e5ba724-0221-40aa-ae43-0303f1a0d91e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 605/605 [02:27<00:00,  4.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.276                 | Train Accuracy:  0.730                 | Val Loss:  0.187                 | Val Accuracy:  0.960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 605/605 [02:27<00:00,  4.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.172                 | Train Accuracy:  0.962                 | Val Loss:  0.072                 | Val Accuracy:  0.987\n"
          ]
        }
      ],
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "                \n",
        "                batch_loss = criterion(output, train_label)\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label)\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "                  \n",
        "EPOCHS = 2\n",
        "model = BertClassifier()\n",
        "LR = 1e-6\n",
        "              \n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83CN8J36RNzw",
        "outputId": "c5e493f3-88ff-4b3c-be9e-d75ac1d4f347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.993\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              \n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "\n",
        "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              total_acc_test += acc\n",
        "    \n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
        "    \n",
        "evaluate(model, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2yW9EejRNzx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.save(model, '/content/model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxdbbWTd01lX",
        "outputId": "7816e13c-91de-4314-e9cd-30e2507b62a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "USrUfy66YArX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nz9uzkPkiuEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78cd70fc-aad5-47de-e7d7-055f8589a5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopword = stopwords.words('russian')\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    ans = ''\n",
        "    for word in words:\n",
        "        if word not in stopword:\n",
        "            ans += word + ' '\n",
        "    \n",
        "    return ans\n",
        "\n",
        "\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "def lemmatize(text):\n",
        "    words = text.split() # разбиваем текст на слова\n",
        "    res = list()\n",
        "    for word in words:\n",
        "        p = morph.parse(word)[0]\n",
        "        res.append(p.normal_form + ' ')\n",
        "\n",
        "    return ''.join(res)\n",
        "\n",
        "\n",
        "\n",
        "def predict(model, text):\n",
        "    text = text.lower() #приводим к нижнему регистру\n",
        "    text = remove_stopwords(text)\n",
        "    text = lemmatize(text)\n",
        "    print(text)\n",
        "\n",
        "    tokenized = tokenizer(text, \n",
        "                padding='max_length', max_length = 512, truncation=True,\n",
        "                return_tensors=\"pt\")\n",
        "    \n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        mask = tokenized['attention_mask'].to(device)\n",
        "        input_id = tokenized['input_ids'].squeeze(1).to(device)\n",
        "        output = model(input_id, mask)\n",
        "    \n",
        "    print(output)\n",
        "    if(output.argmax(dim=1) == 0): return 'study'\n",
        "    if(output.argmax(dim=1) == 1): return 'other'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'гарри поттер моя любимая книга детства и вообще лучшее произведение десятилетия')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "a-eB2SUIdfBw",
        "outputId": "9e541c78-ff6c-4af0-fd63-cea90d5f7226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "гарри поттер любимый книга детство вообще хороший произведение десятилетие \n",
            "tensor([[1.2244, 0.0000]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'Первая полностью российская шапочка из фольги\\\n",
        "                была выпущена на новосибирском заводе «Спецстроймонтаж». Директор предприятия \\\n",
        "                Алексей Джарахов назвал случившееся невероятным успехом, ведь ещё год назад 90% \\\n",
        "                комплектующих поставлялись из-за рубежа.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "y92Ltjrmo59Y",
        "outputId": "fa205bed-f15e-4424-927d-22c5ed65e50c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "первый полностью российский шапочка фольга выпустить новосибирский завод «спецстроймонтаж». директор предприятие алексей джараховый назвать случиться невероятный успехом, ещё год назад 90% комплектующие поставляться из-за рубежа. \n",
            "tensor([[0.1558, 0.2970]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'other'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'Первый канал предложил передать России победу на «Евровидении» из-за масштабных фальсификаций в ходе голосования')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "eOAEUphhqM8Z",
        "outputId": "5b98d52e-dcd8-4364-f6e9-d0dc91fc35fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "первый канал предложить передать россия победа «евровидении» из-за масштабный фальсификация ход голосование \n",
            "tensor([[0.1286, 3.0647]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'other'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'В этом сезоне француз пробил отметку в 100 матчей за «Спартак». \\\n",
        "                Перед уходом в «Марсель» у игрока еще осталось одно незавершенное дело – финал Кубка России: \\\n",
        "                «У меня уже есть идея, как провести прощальный вечер с ребятами, но пока говорить об этом рано. \\\n",
        "                Сейчас у меня одна мечта – поднять трофей над головой, прежде чем отправиться во Францию».')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "8-RX9joTqzH_",
        "outputId": "783ff781-0a3f-4665-c661-4d8f42beedcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "сезон француз пробить отметка 100 матч «спартак». уход «марсель» игрок остаться один незавершённый дело – финал кубок россии: «у идея, провести прощальный вечер ребятами, пока говорить рано. один мечта – поднять трофей головой, прежде отправиться францию». \n",
            "tensor([[0.2382, 0.2811]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'other'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'Наверное, никто не любит сдавать экзамены, но они являются неотъемлемой \\\n",
        "                частью жизни любого школьника или студента. Поэтому стоит потрудиться, чтобы \\\n",
        "                прийти на занятие подготовленным. В этом году свои знания будут защищать до 10,3 тысячи приморцев.\\\n",
        "                Основная часть из них – 9,4 тысячи – выпускники текущего года. Накануне экзаменов в министерстве образования \\\n",
        "                Приморского края напомнили основные правила сдачи ЕГЭ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "DgUmrYuQugkR",
        "outputId": "80e60ee0-c944-442b-e4b4-2bde7d5416cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "наверное, никто любить сдавать экзамены, являться неотъемлемый часть жизнь любой школьник студента. поэтому стоить потрудиться, прийти занятие подготовленным. год свой знание быть защищать 10,3 тысяча приморцев. основный часть – 9,4 тысяча – выпускник текущий года. накануне экзамен министерство образование приморский край напомнить основной правило сдача егэ \n",
            "tensor([[1.8199, 0.0000]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'по мнению опрошенных 31 февраля людей мирэа лучший университет в галактике')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "6tob6Nisu0bV",
        "outputId": "222d3448-c1f4-4898-861f-e48a54b70b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "мнение опросить 31 февраль человек мирэ хороший университет галактика \n",
            "tensor([[1.6238, 0.2853]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'по мнению опрошенных 31 февраля людей мирэа лучший институт в галактике')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "S3yeJnSWu9lY",
        "outputId": "5dafecda-6da0-4564-ba41-7b78310e19ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "мнение опросить 31 февраль человек мирэ хороший институт галактика \n",
            "tensor([[1.3715, 0.5009]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'по мнению опрошенных 31 февраля людей мирэа лучший в галактике')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "8TmjnLJzvESF",
        "outputId": "983d8105-c3d1-4046-97c9-d06ae13edd2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "мнение опросить 31 февраль человек мирэ хороший галактика \n",
            "tensor([[1.0137, 0.7147]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'по мнению опрошенных 31 февраля людей мирэа лучший институт в москве')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lYInvme7vNFb",
        "outputId": "15b36307-6649-4e33-c41f-52f250808835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "мнение опросить 31 февраль человек мирэ хороший институт москва \n",
            "tensor([[1.3093, 0.9033]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'мирэа лучший институт в москве')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "FQB03-OHwfDn",
        "outputId": "c9dd6a5e-6c3f-464c-f509-bae36971c888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "мирэ хороший институт москва \n",
            "tensor([[1.4589, 0.0000]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'мирэа лучший в москве')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lbehhsW8vPgi",
        "outputId": "874bc9e7-2db0-4920-daa4-368c2148ad5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "мирэ хороший москва \n",
            "tensor([[0.8389, 0.0000]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'бармен сказал что это самая лучшая книга по термодинамике которую он когда либо читал ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "EUtEztIOyqb6",
        "outputId": "c62b1207-76ab-4859-e44c-71d58a52a22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "бармен сказать это самый хороший книга термодинамика который либо читать \n",
            "tensor([[1.4665, 0.0000]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'в шашлычной у ашота бармен сказал мне что это самая лучшая книга по термодинамике которую он когда либо читал\\\n",
        "                после этого он взял шампур и сделал харакири')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "24Sil9nI1RjI",
        "outputId": "8c1b108b-4b29-4841-b6af-ac59fc09cc06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "шашлычный ашот бармен сказать это самый хороший книга термодинамика который либо читать взять шампур сделать харакири \n",
            "tensor([[1.8626, 0.0202]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'в шашлычной у ашота бармен сказал мне что это самая лучшая книга про эльфов которую он когда либо читал\\\n",
        "                после этого он взял шампур и сделал харакири')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "VBHLNnG44iOM",
        "outputId": "5f1142ad-b841-4927-e146-a0644792f33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "шашлычный ашот бармен сказать это самый хороший книга эльф который либо читать взять шампур сделать харакири \n",
            "tensor([[1.6143, 0.1765]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'в шашлычной у ашота бармен сказал мне что это самая лучшая газета про эльфов которую он когда либо читал\\\n",
        "                после этого он взял шампур и сделал харакири')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "Y2cG83RU4sDp",
        "outputId": "c9248e31-8726-4f7d-9bd3-832d69fac0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "шашлычный ашот бармен сказать это самый хороший газета эльф который либо читать взять шампур сделать харакири \n",
            "tensor([[1.4169, 0.3872]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'в шашлычной у ашота бармен сказал мне что это самая лучшая газета про эльфов которую он когда либо видел\\\n",
        "                после этого он взял шампур и сделал харакири')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "u3DCo6VD4wA6",
        "outputId": "b3be6ef3-a765-4969-c6f6-dc28eca2062a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "шашлычный ашот бармен сказать это самый хороший газета эльф который либо видеть взять шампур сделать харакири \n",
            "tensor([[1.2055, 1.2228]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'other'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'я учусь в мирэа')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "IcyzRN8L44Kv",
        "outputId": "a4685df0-09d1-418e-e2df-6dac8cf71ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "учиться мирэ \n",
            "tensor([[0.2556, 0.0000]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'мой одногруппник готовился к экзамену 90 секунд')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "jCllC4I35zwU",
        "outputId": "45031323-cc86-4a72-d3fe-6eb3b508cad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "одногруппник готовиться экзамен 90 секунда \n",
            "tensor([[1.2404, 0.0000]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, 'Подскажите пожалуйста, кск принимает экзамен Соколова Л.А.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "LOjiN_kJib14",
        "outputId": "25500653-c094-437a-89e0-3f511a213024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "подсказать пожалуйста, кск принимать экзамен соколов л.а. \n",
            "tensor([[0.4913, 0.0000]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'study'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3ovhQH-Hkhrc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}